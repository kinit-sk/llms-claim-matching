{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    # > 70b params\n",
    "    # Zero-Shot\n",
    "    'mistral-123b-vanilla',\n",
    "    'c4ai-104b-vanilla',\n",
    "    'qwen2_5-72b-vanilla',\n",
    "    'llama3_1-70b-vanilla',\n",
    "\n",
    "    # Zero-Shot + Task\n",
    "    'mistral-123b-instruct',\n",
    "    'c4ai-104b-instruct', \n",
    "    'qwen2_5-72b-instruct',\n",
    "    'llama3_1-70b-instruct',\n",
    "\n",
    "    # Few-Shot + Task\n",
    "    'mistral-123b-fewshot',\n",
    "    'c4ai-104b-fewshot',\n",
    "    'qwen2_5-72b-fewshot',\n",
    "    'llama3_1-70b-fewshot',\n",
    "    \n",
    "    # CoT\n",
    "    'mistral-123b-cot',\n",
    "    'c4ai-104b-cot',\n",
    "    'qwen2_5-72b-cot',\n",
    "    'llama3_1-70b-cot',\n",
    "    \n",
    "    # XLT\n",
    "    'c4ai-104b-xlt',\n",
    "    'mistral-123b-xlt',\n",
    "    'qwen2_5-72b-xlt',\n",
    "    'llama3_1-70b-xlt',\n",
    "\n",
    "    # < 10b params\n",
    "    # Zero-Shot\n",
    "    'llama3_1-8b-vanilla',\n",
    "    'qwen2_5-7b-vanilla',\n",
    "    'mistral-7b-vanilla',\n",
    "\n",
    "    # Zero-Shot + Task\n",
    "    'llama3_1-8b-instruct',\n",
    "    'qwen2_5-7b-instruct',\n",
    "    'mistral-7b-instruct',\n",
    "\n",
    "    # Few-Shot + Task\n",
    "    'llama3_1-8b-fewshot',\n",
    "    'qwen2_5-7b-fewshot',\n",
    "    'mistral-7b-fewshot',\n",
    "\n",
    "    # CoT\n",
    "    'llama3_1-8b-cot',\n",
    "    'qwen2_5-7b-cot',\n",
    "    'mistral-7b-cot',\n",
    "    \n",
    "    # XLT\n",
    "    'llama3_1-8b-xlt',\n",
    "    'qwen2_5-7b-xlt',\n",
    "    'mistral-7b-xlt',\n",
    "\n",
    "    # < 10b params English\n",
    "    # Zero-Shot\n",
    "    'llama3_1-8b-vanilla-en',\n",
    "    'qwen2_5-7b-vanilla-en',\n",
    "    'mistral-7b-vanilla-en',\n",
    "\n",
    "    # Zero-Shot + Task\n",
    "    'llama3_1-8b-instruct-en',\n",
    "    'qwen2_5-7b-instruct-en',\n",
    "    'mistral-7b-instruct-en',\n",
    "\n",
    "    # Few-Shot + Task\n",
    "    'llama3_1-8b-fewshot-en',\n",
    "    'qwen2_5-7b-fewshot-en',\n",
    "    'mistral-7b-fewshot-en',    \n",
    "\n",
    "    # CoT\n",
    "    'llama3_1-8b-cot-en',\n",
    "    'qwen2_5-7b-cot-en',\n",
    "    'mistral-7b-cot-en',\n",
    "\n",
    "    # > 70b params English\n",
    "    # Zero-Shot\n",
    "    'mistral-123b-vanilla-en',\n",
    "    'c4ai-104b-vanilla-en',\n",
    "    'qwen2_5-72b-vanilla-en',\n",
    "    'llama3_1-70b-vanilla-en',\n",
    "\n",
    "    # Zero-Shot + Task\n",
    "    'mistral-123b-instruct-en',\n",
    "    'c4ai-104b-instruct-en',\n",
    "    'qwen2_5-72b-instruct-en',\n",
    "    'llama3_1-70b-instruct-en',\n",
    "\n",
    "    # Few-Shot + Task\n",
    "    'mistral-123b-fewshot-en',\n",
    "    'c4ai-104b-fewshot-en',\n",
    "    'qwen2_5-72b-fewshot-en',\n",
    "    'llama3_1-70b-fewshot-en',\n",
    "    \n",
    "    # CoT\n",
    "    'mistral-123b-cot-en',\n",
    "    'c4ai-104b-cot-en',\n",
    "    'qwen2_5-72b-cot-en',\n",
    "    'llama3_1-70b-cot-en',\n",
    "    \n",
    "]\n",
    "annotated_df = pd.read_csv(f'./datasets/annotation_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\n",
    "    'all',\n",
    "    'spa',\n",
    "    'eng',\n",
    "    'por',\n",
    "    'fra',\n",
    "    'msa',\n",
    "    'deu',\n",
    "    'ara',\n",
    "    'tha',\n",
    "    'hbs',\n",
    "    'kor',\n",
    "    'pol',\n",
    "    'slk',\n",
    "    'nld',\n",
    "    'ron',\n",
    "    'ell',\n",
    "    'ces',\n",
    "    'bul',\n",
    "    'hun',\n",
    "    'hin',\n",
    "    'mya',\n",
    "    'monolingual',\n",
    "    'crosslingual',\n",
    "    'indo-european',\n",
    "    'italic',\n",
    "    'germanic',\n",
    "    'balto-slavic',\n",
    "    'latin',\n",
    "    'non-latin',\n",
    "    'latin-cross',\n",
    "    'mixed-script',\n",
    "    'spa-eng',\n",
    "    'hin-eng',\n",
    "    'eng-ara',\n",
    "    'fra-eng',\n",
    "    'deu-eng',\n",
    "    'eng-por',\n",
    "    'spa-por',\n",
    "    'deu-fra',\n",
    "    'slk-ces',\n",
    "    'slk-eng',\n",
    "    'pol-hbs',\n",
    "    'ces-eng',\n",
    "    'ces-pol',\n",
    "    'nld-deu',\n",
    "    'msa-ara',\n",
    "    'kor-eng',\n",
    "    'mya-msa',\n",
    "    'ara-fra',\n",
    "    'hun-pol',\n",
    "    'tha-por',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./results/metrics', exist_ok=True)\n",
    "for model_name in model_names:\n",
    "    df = pd.read_csv(f'./results/{model_name}.csv')\n",
    "    df['FactCheckLang'] = annotated_df['factcheck_language']\n",
    "    df['PostLang'] = annotated_df['post_language']\n",
    "    df['GroundTruth'] = annotated_df['rating']\n",
    "\n",
    "    # filter out the rows without rating\n",
    "    df = df[~df['GroundTruth'].isna()]\n",
    "    # filter out the rows without prediction\n",
    "    df = df[~df['Prediction'].isna()]\n",
    "    df['YesProb'] = df['YesProb'].apply(lambda x: x if x.startswith('[') else f'[{x}]')\n",
    "    df['NoProb'] = df['NoProb'].apply(lambda x: x if x.startswith('[') else f'[{x}]')\n",
    "    \n",
    "    df['YesProb'] = df['YesProb'].apply(lambda x: eval(x))\n",
    "    df['NoProb'] = df['NoProb'].apply(lambda x: eval(x))\n",
    "    df['YesProb'] = df['YesProb'].apply(lambda x: x[0])\n",
    "    df['NoProb'] = df['NoProb'].apply(lambda x: x[0])\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(columns=['Language', 'AUC', 'Macro F1 (Accuracy)', 'Macro F1', 'Accuracy', 'Precision', 'Recall', 'TNR (irrelevant)', 'FNR (relevant)', 'TPR', 'FPR', 'Bootstrapped Macro F1'])\n",
    "    for language in languages:\n",
    "        if language == 'all':\n",
    "            df_temp = df\n",
    "        elif language == 'monolingual':\n",
    "            df_temp = df[df['FactCheckLang'] == df['PostLang']]\n",
    "        elif language == 'crosslingual':\n",
    "            df_temp = df[df['FactCheckLang'] != df['PostLang']]\n",
    "        elif language == 'indo-european':\n",
    "            langs = ['spa', 'eng', 'por', 'fra', 'deu', 'hbs', 'pol', 'slk', 'nld', 'ron', 'ell', 'ces', 'bul', 'hin']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'italic':\n",
    "            langs = ['spa', 'por', 'fra', 'ron']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'germanic':\n",
    "            langs = ['eng', 'deu', 'nld']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'balto-slavic':\n",
    "            langs = ['hbs', 'ces', 'pol', 'slk', 'bul']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'latin':\n",
    "            langs = ['spa', 'eng', 'por', 'fra', 'msa', 'deu', 'hbs', 'pol', 'slk', 'nld', 'ron', 'ces', 'hun']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'non-latin':\n",
    "            langs = ['ara', 'tha', 'kor', 'ell', 'bul', 'hin', 'mya']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] == df['PostLang'])]\n",
    "        elif language == 'latin-cross':\n",
    "            langs = ['spa', 'eng', 'por', 'fra', 'msa', 'deu', 'hbs', 'pol', 'slk', 'nld', 'ron', 'ces', 'hun']\n",
    "            df_temp = df[(df['FactCheckLang'].isin(langs)) & (df['PostLang'].isin(langs)) & (df['FactCheckLang'] != df['PostLang'])]\n",
    "        elif language == 'mixed-script':\n",
    "            latin = ['spa', 'eng', 'por', 'fra', 'msa', 'deu', 'hbs', 'pol', 'slk', 'nld', 'ron', 'ces', 'hun']\n",
    "            non_latin = ['ara', 'tha', 'kor', 'ell', 'bul', 'hin', 'mya']\n",
    "            df_temp = df[((df['FactCheckLang'].isin(latin) & df['PostLang'].isin(non_latin)) | (df['FactCheckLang'].isin(non_latin) & df['PostLang'].isin(latin)))]\n",
    "        elif '-' not in language:\n",
    "            df_temp = df[(df['FactCheckLang'] == language) & (df['PostLang'] == language)] \n",
    "        else:\n",
    "            post_lang, fc_lang = language.split('-')\n",
    "            df_temp = df[((df['FactCheckLang'] == fc_lang) & (df['PostLang'] == post_lang))]\n",
    "                    \n",
    "        if 'prediction_label' in df_temp.columns:\n",
    "            predictions = df_temp['prediction_label'].values\n",
    "        else:\n",
    "            predictions = df_temp['Prediction'].values\n",
    "        ground_truth = df_temp['GroundTruth'].values\n",
    "        yes_probs = df_temp['YesProb'].values\n",
    "        no_probs = df_temp['NoProb'].values\n",
    "\n",
    "        yes_text = 'Yes'\n",
    "        ground_truth = [1 if p == 'Yes' else 0 for p in ground_truth]\n",
    "        predictions = [1 if p.strip() == yes_text else 0 for p in predictions]\n",
    "\n",
    "        # normalization of yes and no probabilities\n",
    "        for i in range(len(predictions)):\n",
    "            yes_prob = yes_probs[i]\n",
    "            no_prob = no_probs[i]\n",
    "            yes_probs[i] = yes_prob / (yes_prob + no_prob)\n",
    "            no_probs[i] = no_prob / (yes_prob + no_prob)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(ground_truth, yes_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        f1 = f1_score(ground_truth, predictions, average='macro')\n",
    "        \n",
    "        # Number of bootstrap samples\n",
    "        n_bootstraps = 1000\n",
    "        macro_f1_scores = []\n",
    "\n",
    "        # Generate bootstrap samples\n",
    "        for _ in range(n_bootstraps):\n",
    "            # Resample the dataset\n",
    "            indices = resample(range(len(ground_truth)), replace=True)\n",
    "            y_true_resampled = [ground_truth[i] for i in indices]\n",
    "            y_pred_resampled = [predictions[i] for i in indices]\n",
    "\n",
    "            # Compute Macro F1 score for the resampled dataset\n",
    "            score = f1_score(y_true_resampled, y_pred_resampled, average='macro')\n",
    "            macro_f1_scores.append(score)\n",
    "\n",
    "        # Calculate 95% confidence interval\n",
    "        lower = np.percentile(macro_f1_scores, 2.5)\n",
    "        upper = np.percentile(macro_f1_scores, 97.5)\n",
    "        mean_score = np.mean(macro_f1_scores)\n",
    "\n",
    "        accuracy = accuracy_score(ground_truth, predictions)\n",
    "        precision = precision_score(ground_truth, predictions)\n",
    "        recall = recall_score(ground_truth, predictions)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(ground_truth, predictions).ravel()\n",
    "        tnr = tn / (tn + fp)\n",
    "        fnr = fn / (fn + tp)\n",
    "        \n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        f1_accuracy = f'{f1:.2f} ({accuracy:.2f})'\n",
    "        \n",
    "        df_results = pd.concat([\n",
    "            df_results, \n",
    "            pd.DataFrame(\n",
    "                [[language, roc_auc, f1_accuracy, f1, accuracy, precision, recall, tnr, fnr, tpr, fpr, f'({mean_score:.3f}, {lower:.3f}, {upper:.3f})']],\n",
    "                columns=['Language', 'AUC', 'Macro F1 (Accuracy)', 'Macro F1', 'Accuracy', 'Precision', 'Recall', 'TNR (irrelevant)', 'FNR (relevant)', 'TPR', 'FPR', 'Bootstrapped Macro F1'])\n",
    "            ])\n",
    "    df_results = df_results.T\n",
    "    new_header = df_results.iloc[0]\n",
    "    df_results = df_results[1:]\n",
    "    df_results.columns = new_header\n",
    "    df_results.to_csv(f'./results/metrics/{model_name}.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "paths = glob('./results/metrics/*')\n",
    "small = [path for path in paths if ('7b' in path or '8b' in path) and ('-en' not in path)]\n",
    "small_english = [path for path in paths if ('7b' in path or '8b' in path) and ('-en' in path)]\n",
    "large = [path for path in paths if ('7b' not in path and '8b' not in path) and ('-en' not in path)]\n",
    "large_english = [path for path in paths if ('7b' not in path and '8b' not in path) and ('-en' in path)]\n",
    "\n",
    "large_models = [\n",
    "    'mistral-123b',\n",
    "    'c4ai-104b',\n",
    "    'qwen2_5-72b',\n",
    "    'llama3_1-70b',\n",
    "]\n",
    "\n",
    "small_models = [\n",
    "    'llama3_1-8b',\n",
    "    'qwen2_5-7b',\n",
    "    'mistral-7b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def group_chart(data):\n",
    "    # Labels for models and techniques\n",
    "    model_labels = [\n",
    "        \"Mistral-Large\\n123B\", \"C4AI Command R+\\n104B\", \"Qwen2.5\\n72B\", \"Llama3.1\\n70B\",\n",
    "        \"Llama3.1\\n8B\", \"Qwen2.5\\n7B\", \"Mistral\\n7B\"\n",
    "    ]\n",
    "    technique_labels = ['Zero-Shot', 'Zero-Shot +\\nTask description', 'Few-Shot +\\nTask description', 'CoT', 'XLT']\n",
    "\n",
    "    # Prepare the figure\n",
    "    num_bars = len(technique_labels)  # Number of techniques\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    colors = ['b', 'r', 'g', 'm', 'c']\n",
    "    bar_width = 0.15\n",
    "\n",
    "    x = np.arange(len(model_labels))  # Positions for the groups (models)\n",
    "\n",
    "    for i, (tech_data, color) in enumerate(zip(data, colors)):\n",
    "        current_data = [item[0] for item in tech_data]\n",
    "        lower_bound = [item[0] - item[1] for item in tech_data]\n",
    "        upper_bound = [item[2] - item[0] for item in tech_data]\n",
    "        ax.bar(x + i * bar_width, current_data, bar_width, label=technique_labels[i], color=color, alpha=0.7, yerr=[lower_bound, upper_bound], capsize=5)\n",
    "        # Add numbers on top of the bars, positioned slightly higher to avoid overlap\n",
    "        for j, value in enumerate(current_data):\n",
    "            ax.text(\n",
    "                x[j] + i * bar_width,\n",
    "                value + 2,  # Adjust height to avoid overlap\n",
    "                f'{value:.0f}',\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8,\n",
    "                fontweight='bold',\n",
    "            )\n",
    "\n",
    "    # ax.set_title(\"Performance of Techniques Across Models\", fontsize=14)\n",
    "    ax.set_xticks(x + (num_bars - 1) * bar_width / 2)\n",
    "    ax.set_xticklabels(model_labels, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_ylabel(\"Macr F1 Score\", fontsize=12)\n",
    "    ax.set_ylim(40, 90)\n",
    "    \n",
    "    separator_position = 3.8\n",
    "    ax.axvline(separator_position, color='black', linestyle='--', linewidth=2, label='_nolegend_')\n",
    "    plt.text(separator_position - 2, 91, '70B+ LLMs', ha='center', fontsize=12, fontweight='bold')\n",
    "    plt.text(separator_position + 1.7, 91, '10B- LLMs', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Add legend below the chart\n",
    "    fig.legend(technique_labels, loc='lower center', ncol=num_bars, fontsize=12, frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "\n",
    "    # Save or show the plot\n",
    "    plt.savefig('overall_results-grouped.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "metric = 'Bootstrapped Macro F1'\n",
    "lang_comb = 'all'\n",
    "all_data = [\n",
    "    [np.asarray(eval(pd.read_csv(f'./results/metrics/{model}-vanilla.csv', index_col=0).at[metric, lang_comb])) * 100 for model in large_models + small_models],\n",
    "    [np.asarray(eval(pd.read_csv(f'./results/metrics/{model}-instruct.csv', index_col=0).at[metric, lang_comb])) * 100 for model in large_models + small_models],\n",
    "    [np.asarray(eval(pd.read_csv(f'./results/metrics/{model}-fewshot.csv', index_col=0).at[metric, lang_comb])) * 100 for model in large_models + small_models],\n",
    "    [np.asarray(eval(pd.read_csv(f'./results/metrics/{model}-cot.csv', index_col=0).at[metric, lang_comb])) * 100 for model in large_models + small_models],\n",
    "    [np.asarray(eval(pd.read_csv(f'./results/metrics/{model}-xlt.csv', index_col=0).at[metric, lang_comb])) * 100 for model in large_models + small_models],\n",
    "]\n",
    "\n",
    "group_chart(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = large_models + small_models\n",
    "strategies = ['vanilla', 'instruct', 'fewshot', 'cot']\n",
    "\n",
    "data_matrix = []\n",
    "for model in models:\n",
    "    model_data = []\n",
    "    for strategy in strategies:\n",
    "        org = float(pd.read_csv(f'./results/metrics/{model}-{strategy}.csv', index_col=0).at['Macro F1', 'all']) * 100\n",
    "        eng = float(pd.read_csv(f'./results/metrics/{model}-{strategy}-en.csv', index_col=0).at['Macro F1', 'all']) * 100\n",
    "        model_data.append(eng - org)\n",
    "    data_matrix.append(model_data)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(7, 5)})\n",
    "sns.heatmap(\n",
    "    data_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\", \n",
    "    xticklabels=['Zero-Shot', 'Zero-Shot\\nTask Description', 'Few-Shot\\nTask Description', 'CoT'],\n",
    "    yticklabels=['Mistral-Large\\n123B', 'C4AI Command R+\\n104B', 'Qwen2.5\\n72B', 'Llama3.1\\n70B', 'Llama3.1\\n8B', 'Qwen2.5\\n7B', 'Mistral\\n7B'],\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    cbar_kws={'label': 'Macro F1 Score Difference (%)'}\n",
    ")\n",
    "\n",
    "plt.annotate('', xy=(1.35, 0.6), xytext=(1.35, 0.45), \n",
    "            xycoords='axes fraction', textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', width=2, headwidth=10, headlength=10))\n",
    "\n",
    "\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().set_xticklabels(\n",
    "    plt.gca().get_xticklabels(),\n",
    "    rotation=30,\n",
    "    ha='left',\n",
    "    rotation_mode='anchor'\n",
    ")\n",
    "\n",
    "plt.gca().yaxis.set_tick_params(pad=50)\n",
    "plt.gca().set_yticklabels(plt.gca().get_yticklabels(), rotation=0, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('heatmap-org-vs-eng.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grouped_charts_in_grid(data, save_as=None, n_cols=9, figsize=(20, 7)):\n",
    "    unique_techniques = data[\"Technique\"].unique()\n",
    "    unique_models = data[\"Model\"].unique()\n",
    "    data[\"Technique\"] = pd.Categorical(data[\"Technique\"], categories=unique_techniques, ordered=True)\n",
    "    data[\"Model\"] = pd.Categorical(data[\"Model\"], categories=unique_models, ordered=True)\n",
    "    \n",
    "    languages = data[\"Language\"].unique()\n",
    "    \n",
    "    n_languages = len(languages)\n",
    "    n_rows = (n_languages + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, constrained_layout=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    legend_elements = []\n",
    "    \n",
    "\n",
    "    for idx, language in enumerate(languages):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "\n",
    "        lang_data = data[data[\"Language\"] == language]\n",
    "        \n",
    "        pivot_data = lang_data.pivot(index=\"Technique\", columns=\"Model\", values=\"Performance\")\n",
    "        pivot_data = pivot_data.reindex(index=unique_techniques, columns=unique_models)  # Maintain order\n",
    "        \n",
    "        # Plot settings\n",
    "        techniques = pivot_data.index\n",
    "        n_bars = len(unique_models)\n",
    "        bar_width = 0.8 / n_bars\n",
    "        x = np.arange(len(techniques))\n",
    "\n",
    "        for i, model in enumerate(unique_models):\n",
    "            bars = ax.bar(\n",
    "                x + i * bar_width, \n",
    "                pivot_data[model], \n",
    "                bar_width, \n",
    "                label=model if idx == 0 else None\n",
    "            )\n",
    "            if idx == 0:\n",
    "                legend_elements.append(\n",
    "                    (bars[0], model)\n",
    "                )\n",
    "        \n",
    "        ax.set_title(language, fontsize=10)\n",
    "        ax.set_xticks(x + (n_bars - 1) * bar_width / 2)\n",
    "        ax.set_xticklabels(techniques, rotation=45, ha=\"right\", fontsize=8)\n",
    "        ax.tick_params(axis=\"y\", labelsize=8)\n",
    "        ax.set_ylim(20, 100)\n",
    "        \n",
    "        ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        if idx % n_cols == 0:\n",
    "            ax.set_ylabel(\"Macro F1\")\n",
    "        \n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for ax in axes[n_languages:]:\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    if n_languages % n_cols != 0:\n",
    "        empty_ax = axes[-1] \n",
    "        empty_ax.axis(\"off\")\n",
    "        empty_ax.legend(\n",
    "            handles=[elem[0] for elem in legend_elements],\n",
    "            labels=[elem[1] for elem in legend_elements],\n",
    "            title=\"Models\",\n",
    "            loc=\"center\",\n",
    "            fontsize=10,\n",
    "            title_fontsize=12,\n",
    "        )\n",
    "    else:\n",
    "        fig.legend(\n",
    "            unique_models, \n",
    "            title=\"Models\", \n",
    "            loc=\"upper center\", \n",
    "            bbox_to_anchor=(0.5, 0), \n",
    "            ncol=4, fontsize=10\n",
    ")\n",
    "\n",
    "    # Save or show the plot\n",
    "    if save_as:\n",
    "        plt.savefig(save_as, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'Macro F1'\n",
    "languages = [\n",
    "    'spa', #\n",
    "    'eng', #\n",
    "    'por',\n",
    "    'fra',\n",
    "    'msa',\n",
    "    'deu',\n",
    "    'ara', #\n",
    "    'tha',\n",
    "    'hbs',\n",
    "    'kor',\n",
    "    'pol',\n",
    "    'slk', #\n",
    "    'nld',\n",
    "    'ron',\n",
    "    'ell',\n",
    "    'ces',\n",
    "    'bul',\n",
    "    'hun',\n",
    "    'hin',\n",
    "    'mya', #\n",
    "]\n",
    "\n",
    "languages = sorted(languages)\n",
    "\n",
    "\n",
    "models = [\"mistral-123b\", \"c4ai-104b\", \"qwen2_5-72b\", \"llama3_1-70b\"]\n",
    "techniques = [\"vanilla\", \"instruct\", \"fewshot\", \"cot\", \"xlt\"]\n",
    "\n",
    "data = pd.DataFrame([\n",
    "    {\"Language\": lang, \"Model\": model, \"Technique\": tech, \"Performance\": float(pd.read_csv(f'./results/metrics/{model}-{tech}.csv', index_col=0).at[metric, lang]) * 100}\n",
    "    for lang in languages for model in models for tech in techniques\n",
    "])\n",
    "\n",
    "# reanme the models\n",
    "data[\"Model\"] = data[\"Model\"].replace({\n",
    "    \"mistral-123b\": \"Mistral Large 123B\",\n",
    "    \"c4ai-104b\": \"C4AI Command R+ 104B\",\n",
    "    \"qwen2_5-72b\": \"Qwen2.5 72B Instruct\",\n",
    "    \"llama3_1-70b\": \"Llama3.1 70B Instruct\"\n",
    "})\n",
    "\n",
    "# rename the techniques\n",
    "data[\"Technique\"] = data[\"Technique\"].replace({\n",
    "    \"vanilla\": \"ZS\",\n",
    "    \"instruct\": \"ZS + Task\",\n",
    "    \"fewshot\": \"FW + Task\",\n",
    "    \"cot\": \"CoT\",\n",
    "    \"xlt\": \"XLT\"\n",
    "})\n",
    "\n",
    "# Generate the charts\n",
    "create_grouped_charts_in_grid(data, n_cols=7, save_as=\"large_language_analysis-part.pdf\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def create_heatmap(df, save_as=None, figsize=(10, 10)):\n",
    "    pivot_df = df.pivot(index='Model', columns='Language', values='Performance')\n",
    "    pivot_df.columns = pivot_df.columns.map({\n",
    "        'ara': 'ara*',\n",
    "        'bul': 'bul*',\n",
    "        'ces': 'ces',\n",
    "        'deu': 'deu',\n",
    "        'ell': 'ell*',\n",
    "        'eng': 'eng',\n",
    "        'fra': 'fra',\n",
    "        'hbs': 'hbs',\n",
    "        'hin': 'hin*',\n",
    "        'hun': 'hun',\n",
    "        'kor': 'kor*',\n",
    "        'msa': 'msa',\n",
    "        'mya': 'mya*',\n",
    "        'nld': 'nld',\n",
    "        'pol': 'pol',\n",
    "        'por': 'por',\n",
    "        'ron': 'ron',\n",
    "        'slk': 'slk',\n",
    "        'spa': 'spa',\n",
    "        'tha': 'tha*',\n",
    "        'spa-eng': 'spa-eng',\n",
    "        'hin-eng': 'hin*-eng',\n",
    "        'eng-ara': 'eng-ara*',\n",
    "        'fra-eng': 'fra-eng',\n",
    "        'deu-eng': 'deu-eng',\n",
    "        'eng-por': 'eng-por',\n",
    "        'spa-por': 'spa-por',\n",
    "        'deu-fra': 'deu-fra',\n",
    "        'slk-ces': 'slk-ces',\n",
    "        'slk-eng': 'slk-eng',\n",
    "        'pol-hbs': 'pol-hbs',\n",
    "        'ces-eng': 'ces-eng',\n",
    "        'ces-pol': 'ces-pol',\n",
    "        'nld-deu': 'nld-deu',\n",
    "        'msa-ara': 'msa-ara*',\n",
    "        'kor-eng': 'kor*-eng',\n",
    "        'mya-msa': 'mya*-msa',\n",
    "        'ara-fra': 'ara*-fra',\n",
    "        'hun-pol': 'hun-pol',\n",
    "        'tha-por': 'tha*-por',\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.0f', cbar_kws={\"pad\": 0.02, \"shrink\": 1})\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.axvline(x=0, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)    \n",
    "    plt.axvline(x=4, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=7, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=12, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=14, color='black', linewidth=2, ymin=0, ymax=1.15, clip_on=False)\n",
    "    plt.axvline(x=20, color='black', linewidth=4, ymin=0, ymax=1.15, clip_on=False)\n",
    "    \n",
    "    plt.text(2.25, -0.25, 'Italic', fontsize=10, ha='center', va='center')\n",
    "    plt.text(5.55, -0.25, 'Germanic', fontsize=10, ha='center', va='center')\n",
    "    plt.text(9.75, -0.25, 'Slavic', fontsize=10, ha='center', va='center')\n",
    "    \n",
    "    plt.text(6.5, -0.8, 'Indo-European', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "    plt.text(17, -0.8, 'Others', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "    plt.text(30, -0.8, 'Cross-Lingual Pairs', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "    if save_as:\n",
    "        plt.savefig(save_as, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "languages = [\n",
    "    'ara', 'bul', 'ces', 'deu', 'ell', 'eng', 'fra', 'hbs', 'hin', 'hun', 'kor', 'msa', 'mya', 'nld', 'pol', 'por', 'ron', 'slk', 'spa', 'tha',\n",
    "    'spa-eng',\n",
    "    'hin-eng',\n",
    "    'eng-ara',\n",
    "    'fra-eng',\n",
    "    'deu-eng',\n",
    "    'eng-por',\n",
    "    'spa-por',\n",
    "    'deu-fra',\n",
    "    'slk-ces',\n",
    "    'slk-eng',\n",
    "    'pol-hbs',\n",
    "    'ces-eng',\n",
    "    'ces-pol',\n",
    "    'nld-deu',\n",
    "    'msa-ara',\n",
    "    'kor-eng',\n",
    "    'mya-msa',\n",
    "    'ara-fra',\n",
    "    'hun-pol',\n",
    "    'tha-por',\n",
    "]\n",
    "        \n",
    "models = [\"mistral-123b\", \"c4ai-104b\", \"qwen2_5-72b\", \"llama3_1-70b\", \"llama3_1-8b\", \"qwen2_5-7b\", \"mistral-7b\"]\n",
    "techniques = [\"vanilla\", \"instruct\", \"fewshot\", \"cot\", \"xlt\"]\n",
    "\n",
    "data = pd.DataFrame([\n",
    "    {\"Language\": lang, \"Model\": model, \"Technique\": tech, \"Performance\": float(pd.read_csv(f'./results/metrics/{model}-{tech}.csv', index_col=0).at[metric, lang]) * 100}\n",
    "    for lang in languages for model in models for tech in techniques\n",
    "])\n",
    "\n",
    "data[\"Model\"] = data[\"Model\"].replace({\n",
    "    \"mistral-123b\": \"Mistral Large\\n123B\",\n",
    "    \"c4ai-104b\": \"C4AI Command R+\\n104B\",\n",
    "    \"qwen2_5-72b\": \"Qwen2.5\\n72B\",\n",
    "    \"llama3_1-70b\": \"Llama3.1\\n70B\",\n",
    "    \"llama3_1-8b\": \"Llama3.1\\n8B\",\n",
    "    \"qwen2_5-7b\": \"Qwen2.5\\n7B\",\n",
    "    \"mistral-7b\": \"Mistral\\n7B\"\n",
    "})\n",
    "\n",
    "data[\"Technique\"] = data[\"Technique\"].replace({\n",
    "    \"vanilla\": \"ZS\",\n",
    "    \"instruct\": \"ZS + Task\",\n",
    "    \"fewshot\": \"FW + Task\",\n",
    "    \"cot\": \"CoT\",\n",
    "    \"xlt\": \"XLT\"\n",
    "})\n",
    "\n",
    "data[\"Model\"] = pd.Categorical(data[\"Model\"], categories=[\"Mistral Large\\n123B\", \"C4AI Command R+\\n104B\", \"Qwen2.5\\n72B\", \"Qwen2.5\\n7B\", \"Llama3.1\\n70B\", \"Mistral\\n7B\", \"Llama3.1\\n8B\"], ordered=True)\n",
    "\n",
    "data[\"Language\"] = pd.Categorical(data[\"Language\"], categories=[\n",
    "    'fra', 'por', 'ron', 'spa', 'deu', 'eng', 'nld', 'bul', 'ces', 'hbs', 'pol', 'slk', 'ell', 'hin', 'ara', 'hun', 'kor', 'msa', 'mya', 'tha', \n",
    "    'spa-eng',\n",
    "    'hin-eng',\n",
    "    'eng-ara',\n",
    "    'fra-eng',\n",
    "    'deu-eng',\n",
    "    'eng-por',\n",
    "    'spa-por',\n",
    "    'deu-fra',\n",
    "    'slk-ces',\n",
    "    'slk-eng',\n",
    "    'pol-hbs',\n",
    "    'ces-eng',\n",
    "    'ces-pol',\n",
    "    'nld-deu',\n",
    "    'msa-ara',\n",
    "    'kor-eng',\n",
    "    'mya-msa',\n",
    "    'ara-fra',\n",
    "    'hun-pol',\n",
    "    'tha-por',\n",
    "], ordered=True)\n",
    "\n",
    "average_performance = data.groupby([\"Model\", 'Language'])[\"Performance\"].mean().reset_index()\n",
    "\n",
    "create_heatmap(average_performance, figsize=(20, 3.5), save_as=\"language_analysis_overall2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def create_heatmap(df, save_as=None, figsize=(10, 10)):\n",
    "    pivot_df = df.pivot(index='Technique', columns='Language', values='Performance')\n",
    "    pivot_df.columns = pivot_df.columns.map({\n",
    "        'ara': 'ara*',\n",
    "        'bul': 'bul*',\n",
    "        'ces': 'ces',\n",
    "        'deu': 'deu',\n",
    "        'ell': 'ell*',\n",
    "        'eng': 'eng',\n",
    "        'fra': 'fra',\n",
    "        'hbs': 'hbs',\n",
    "        'hin': 'hin*',\n",
    "        'hun': 'hun',\n",
    "        'kor': 'kor*',\n",
    "        'msa': 'msa',\n",
    "        'mya': 'mya*',\n",
    "        'nld': 'nld',\n",
    "        'pol': 'pol',\n",
    "        'por': 'por',\n",
    "        'ron': 'ron',\n",
    "        'slk': 'slk',\n",
    "        'spa': 'spa',\n",
    "        'tha': 'tha*',\n",
    "        'spa-eng': 'spa-eng',\n",
    "        'hin-eng': 'hin*-eng',\n",
    "        'eng-ara': 'eng-ara*',\n",
    "        'fra-eng': 'fra-eng',\n",
    "        'deu-eng': 'deu-eng',\n",
    "        'eng-por': 'eng-por',\n",
    "        'spa-por': 'spa-por',\n",
    "        'deu-fra': 'deu-fra',\n",
    "        'slk-ces': 'slk-ces',\n",
    "        'slk-eng': 'slk-eng',\n",
    "        'pol-hbs': 'pol-hbs',\n",
    "        'ces-eng': 'ces-eng',\n",
    "        'ces-pol': 'ces-pol',\n",
    "        'nld-deu': 'nld-deu',\n",
    "        'msa-ara': 'msa-ara*',\n",
    "        'kor-eng': 'kor*-eng',\n",
    "        'mya-msa': 'mya*-msa',\n",
    "        'ara-fra': 'ara*-fra',\n",
    "        'hun-pol': 'hun-pol',\n",
    "        'tha-por': 'tha*-por',\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.0f', cbar_kws={\"pad\": 0.02, \"shrink\": 1})\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.axvline(x=0, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)    \n",
    "    plt.axvline(x=4, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=7, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=12, color='black', linewidth=2, linestyle='--', ymax=1.075, clip_on=False)\n",
    "    plt.axvline(x=14, color='black', linewidth=2, ymin=0, ymax=1.15, clip_on=False)\n",
    "\n",
    "    plt.text(2.25, -0.25, 'Italic', fontsize=10, ha='center', va='center')\n",
    "    plt.text(5.55, -0.25, 'Germanic', fontsize=10, ha='center', va='center')\n",
    "    plt.text(9.75, -0.25, 'Slavic', fontsize=10, ha='center', va='center')\n",
    "    \n",
    "    plt.text(6.5, -0.8, 'Indo-European', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "    plt.text(17, -0.8, 'Others', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "    # Save or show the plot\n",
    "    if save_as:\n",
    "        plt.savefig(save_as, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "languages = [\n",
    "    'ara', 'bul', 'ces', 'deu', 'ell', 'eng', 'fra', 'hbs', 'hin', 'hun', 'kor', 'msa', 'mya', 'nld', 'pol', 'por', 'ron', 'slk', 'spa', 'tha',\n",
    "]\n",
    "        \n",
    "models = [\"mistral-123b\", \"c4ai-104b\", \"qwen2_5-72b\", \"llama3_1-70b\", \"llama3_1-8b\", \"qwen2_5-7b\", \"mistral-7b\"]\n",
    "techniques = [\"vanilla\", \"instruct\", \"fewshot\", \"cot\", \"xlt\"]\n",
    "\n",
    "data = pd.DataFrame([\n",
    "    {\"Language\": lang, \"Model\": model, \"Technique\": tech, \"Performance\": float(pd.read_csv(f'./results/metrics/{model}-{tech}.csv', index_col=0).at[metric, lang]) * 100}\n",
    "    for lang in languages for model in models for tech in techniques\n",
    "])\n",
    "\n",
    "data[\"Model\"] = data[\"Model\"].replace({\n",
    "    \"mistral-123b\": \"Mistral Large\\n123B\",\n",
    "    \"c4ai-104b\": \"C4AI Command R+\\n104B\",\n",
    "    \"qwen2_5-72b\": \"Qwen2.5\\n72B\",\n",
    "    \"llama3_1-70b\": \"Llama3.1\\n70B\",\n",
    "    \"llama3_1-8b\": \"Llama3.1\\n8B\",\n",
    "    \"qwen2_5-7b\": \"Qwen2.5\\n7B\",\n",
    "    \"mistral-7b\": \"Mistral\\n7B\"\n",
    "})\n",
    "\n",
    "data[\"Technique\"] = data[\"Technique\"].replace({\n",
    "    \"vanilla\": \"ZS\",\n",
    "    \"instruct\": \"ZS + Task\",\n",
    "    \"fewshot\": \"FW + Task\",\n",
    "    \"cot\": \"CoT\",\n",
    "    \"xlt\": \"XLT\"\n",
    "})\n",
    "\n",
    "data[\"Model\"] = pd.Categorical(data[\"Model\"], categories=[\"Mistral Large\\n123B\", \"C4AI Command R+\\n104B\", \"Qwen2.5\\n72B\", \"Qwen2.5\\n7B\", \"Llama3.1\\n70B\", \"Mistral\\n7B\", \"Llama3.1\\n8B\"], ordered=True)\n",
    "data[\"Technique\"] = pd.Categorical(data[\"Technique\"], categories=[\"ZS + Task\", \"CoT\", \"XLT\", \"FW + Task\", \"ZS\"], ordered=True)\n",
    "data[\"Language\"] = pd.Categorical(data[\"Language\"], categories=[\n",
    "    'fra', 'por', 'ron', 'spa', 'deu', 'eng', 'nld', 'bul', 'ces', 'hbs', 'pol', 'slk', 'ell', 'hin', 'ara', 'hun', 'kor', 'msa', 'mya', 'tha', \n",
    "], ordered=True)\n",
    "\n",
    "average_performance = data.groupby([\"Technique\", 'Language'])[\"Performance\"].mean().reset_index()\n",
    "\n",
    "create_heatmap(average_performance, figsize=(10, 2.5), save_as=\"language_analysis_techniques.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_horizontal_bar_charts_for_languages(\n",
    "    data, \n",
    "    save_as=None,\n",
    "    n_cols=5,\n",
    "):\n",
    "    unique_techniques = data[\"Technique\"].unique()\n",
    "    unique_languages = data[\"Language\"].unique()\n",
    "    unique_models = data[\"Model\"].unique()\n",
    "\n",
    "    data[\"Technique\"] = pd.Categorical(data[\"Technique\"], categories=unique_techniques, ordered=True)\n",
    "    data[\"Language\"] = pd.Categorical(data[\"Language\"], categories=unique_languages, ordered=True)\n",
    "    data[\"Model\"] = pd.Categorical(data[\"Model\"], categories=unique_models, ordered=True)\n",
    "\n",
    "    n_languages = len(unique_languages)\n",
    "    n_rows = -(-n_languages // n_cols)\n",
    "    \n",
    "    if len(unique_models) < 5:\n",
    "        figsize = (15,22)\n",
    "    else:\n",
    "        figsize = (15, 25)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, language in enumerate(unique_languages):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        lang_data = data[data[\"Language\"] == language]\n",
    "        lang_data[\"Model_Technique\"] = lang_data[\"Model\"].astype(str) + \" - \" + lang_data[\"Technique\"].astype(str)\n",
    "        lang_data = lang_data.sort_values(by=\"Performance\", ascending=True)\n",
    "        \n",
    "        ax.barh(lang_data[\"Model_Technique\"], lang_data[\"Performance\"], color='skyblue')\n",
    "        \n",
    "        ax.set_title(language, fontsize=12)\n",
    "        ax.set_xlabel(\"Performance\", fontsize=10)\n",
    "        ax.tick_params(axis=\"y\", labelsize=8)\n",
    "        ax.tick_params(axis=\"x\", labelsize=8)\n",
    "        ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "        \n",
    "        if idx % n_cols == 0:\n",
    "            ax.set_ylabel(\"Model - Technique\", fontsize=10)\n",
    "        \n",
    "    for ax in axes[n_languages:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    if save_as:\n",
    "        plt.savefig(save_as, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\n",
    "    'spa',\n",
    "    'eng',\n",
    "    'por',\n",
    "    'fra',\n",
    "    'msa',\n",
    "    'deu',\n",
    "    'ara',\n",
    "    'tha',\n",
    "    'hbs',\n",
    "    'kor',\n",
    "    'pol',\n",
    "    'slk',\n",
    "    'nld',\n",
    "    'ron',\n",
    "    'ell',\n",
    "    'ces',\n",
    "    'bul',\n",
    "    'hun',\n",
    "    'hin',\n",
    "    'mya',\n",
    "]\n",
    "\n",
    "languages = sorted(languages)\n",
    "models = [\"mistral-123b\", \"c4ai-104b\", \"qwen2_5-72b\", \"llama3_1-70b\"]\n",
    "techniques = [\"vanilla\", \"instruct\", \"fewshot\", \"cot\", \"xlt\"]\n",
    "\n",
    "data = pd.DataFrame([\n",
    "    {\"Language\": lang, \"Model\": model, \"Technique\": tech, \"Performance\": float(pd.read_csv(f'./results/metrics/{model}-{tech}.csv', index_col=0).at[metric, lang]) * 100}\n",
    "    for lang in languages for model in models for tech in techniques\n",
    "])\n",
    "\n",
    "data[\"Model\"] = data[\"Model\"].replace({\n",
    "    \"mistral-123b\": \"Mistral Large 123B\",\n",
    "    \"c4ai-104b\": \"C4AI Command R+ 104B\",\n",
    "    \"qwen2_5-72b\": \"Qwen2.5 72B Instruct\",\n",
    "    \"llama3_1-70b\": \"Llama3.1 70B Instruct\"\n",
    "})\n",
    "\n",
    "data[\"Technique\"] = data[\"Technique\"].replace({\n",
    "    \"vanilla\": \"ZS\",\n",
    "    \"instruct\": \"ZS + Task\",\n",
    "    \"fewshot\": \"FW + Task\",\n",
    "    \"cot\": \"CoT\",\n",
    "    \"xlt\": \"XLT\"\n",
    "})\n",
    "\n",
    "create_horizontal_bar_charts_for_languages(\n",
    "    data, \n",
    "    n_cols=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disai-multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
